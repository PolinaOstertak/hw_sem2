{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "Попробуйте поработать с датасетом юридических текстов. В датасете всего две важных колонки признаков: заголовок дела и его текст, а целевая переменная - case_outcome (мультиклассовая классификация).\n",
    "\n",
    "В базовом варианте можно оставить только текст дела, если хотите поинтереснее - можно попробовать распарсить case_title, добыв оттуда дополнительные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \n",
       "0  Ordinarily that discretion will be exercised s...  \n",
       "1  The general principles governing the exercise ...  \n",
       "2  Ordinarily that discretion will be exercised s...  \n",
       "3  The general principles governing the exercise ...  \n",
       "4  The preceding general principles inform the ex...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('legal_text_classification.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_text    0.704423\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "# проверяю есть ли пропуски\n",
    "missing_values = data.isnull().sum().sort_values(ascending = False)\n",
    "missing_values = missing_values[missing_values > 0] / data.shape[0]\n",
    "print(f'{missing_values * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>Case25203</td>\n",
       "      <td>cited</td>\n",
       "      <td>Reches Pty Ltd v Tadiran Pty Ltd (1998) 85 FCR...</td>\n",
       "      <td>That is not confined to persons who control th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>Case25204</td>\n",
       "      <td>cited</td>\n",
       "      <td>Sir Lindsay Parkinson &amp;amp; Co Ltd v Triplan L...</td>\n",
       "      <td>Once the threshold prescribed by s 1335 is sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>Case25205</td>\n",
       "      <td>cited</td>\n",
       "      <td>Spiel v Commodity Brokers Australia Pty Ltd (I...</td>\n",
       "      <td>Once the threshold prescribed by s 1335 is sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>Case25206</td>\n",
       "      <td>distinguished</td>\n",
       "      <td>Tullock Ltd v Walker (Unreported, Supreme Cour...</td>\n",
       "      <td>Given the extent to which Deumer stands to gai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>Case25207</td>\n",
       "      <td>distinguished</td>\n",
       "      <td>Yandil Holdings Pty Ltd v Insurance Co of Nort...</td>\n",
       "      <td>In my view, it is clear that the Court may do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         case_id   case_outcome  \\\n",
       "0          Case1          cited   \n",
       "1          Case2          cited   \n",
       "2          Case3          cited   \n",
       "3          Case4          cited   \n",
       "4          Case5          cited   \n",
       "...          ...            ...   \n",
       "24980  Case25203          cited   \n",
       "24981  Case25204          cited   \n",
       "24982  Case25205          cited   \n",
       "24983  Case25206  distinguished   \n",
       "24984  Case25207  distinguished   \n",
       "\n",
       "                                              case_title  \\\n",
       "0      Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1      Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2      Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3      Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4      Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "...                                                  ...   \n",
       "24980  Reches Pty Ltd v Tadiran Pty Ltd (1998) 85 FCR...   \n",
       "24981  Sir Lindsay Parkinson &amp; Co Ltd v Triplan L...   \n",
       "24982  Spiel v Commodity Brokers Australia Pty Ltd (I...   \n",
       "24983  Tullock Ltd v Walker (Unreported, Supreme Cour...   \n",
       "24984  Yandil Holdings Pty Ltd v Insurance Co of Nort...   \n",
       "\n",
       "                                               case_text  \n",
       "0      Ordinarily that discretion will be exercised s...  \n",
       "1      The general principles governing the exercise ...  \n",
       "2      Ordinarily that discretion will be exercised s...  \n",
       "3      The general principles governing the exercise ...  \n",
       "4      The preceding general principles inform the ex...  \n",
       "...                                                  ...  \n",
       "24980  That is not confined to persons who control th...  \n",
       "24981  Once the threshold prescribed by s 1335 is sat...  \n",
       "24982  Once the threshold prescribed by s 1335 is sat...  \n",
       "24983  Given the extent to which Deumer stands to gai...  \n",
       "24984  In my view, it is clear that the Court may do ...  \n",
       "\n",
       "[24809 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(axis = 0, how ='any') # удаляю стоки с пропусками\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ordinarily that discretion will be exercised s...\n",
       "1    The general principles governing the exercise ...\n",
       "2    Ordinarily that discretion will be exercised s...\n",
       "3    The general principles governing the exercise ...\n",
       "4    The preceding general principles inform the ex...\n",
       "Name: case_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['case_outcome']\n",
    "X = data['case_text']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(choice_transformer, choice_ngrams):\n",
    "    \n",
    "     text_features = 'case_text'\n",
    "    \n",
    "     \n",
    "     if choice_transformer == 'tfidf':\n",
    "        text_transformer = TfidfVectorizer(ngram_range=choice_ngrams, tokenizer=word_tokenize, stop_words='english')\n",
    "     else:\n",
    "        text_transformer = CountVectorizer(ngram_range=choice_ngrams, tokenizer=word_tokenize, stop_words='english')\n",
    "     \n",
    "     preprocessor = text_transformer\n",
    "     return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(model):\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    \n",
    "    ypredtest = model.predict(Xtest)\n",
    "    ypredtrain = model.predict(Xtrain)\n",
    "    \n",
    "    print(accuracy_score(ytest, ypredtest), accuracy_score(ytrain, ypredtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF unigrams\n",
    "\n",
    "preprocessor = feature_engineering('tfidf', (1, 1))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5511890366787585 0.6564720108832569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5916968964127368 0.8118103491711594\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF bigrams\n",
    "preprocessor = feature_engineering('tfidf', (2, 2))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5669085046352277 0.7050435834131102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5872632003224506 0.8824003627752305\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW unigrams\n",
    "\n",
    "preprocessor = feature_engineering('bow', (1, 1))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5004030632809351 0.5304580037285233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4943571140669085 0.5086411044490351\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW bigrams\n",
    "\n",
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792019347037485 0.9006902806469491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5219669488109633 0.6673048823499773\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW Bagging\n",
    "\n",
    "preprocessor = feature_engineering('bow', (1, 1))\n",
    "\n",
    "bagging = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BaggingClassifier())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5652962515114873 0.9418551922204867\n"
     ]
    }
   ],
   "source": [
    "modelfit(bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "bagging = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BaggingClassifier())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5878677952438532 0.9342973749181236\n"
     ]
    }
   ],
   "source": [
    "modelfit(bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(n_jobs=-1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5939137444578799 0.9568196704791656\n"
     ]
    }
   ],
   "source": [
    "modelfit(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом результаты вышли не очень хорошие. Значения accuracy на тестовой выборке в большинстве случаев значительно выше, чем на трейне. Неплохие значения показывает BOW unigrams. А так же логистическая регрессия в TF-IDF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
